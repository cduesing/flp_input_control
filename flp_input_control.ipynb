{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "QEBDECAa3KNp",
   "metadata": {
    "id": "QEBDECAa3KNp"
   },
   "source": [
    "# Demonstration for Region North"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Eq54jOIPAqzw",
   "metadata": {
    "id": "Eq54jOIPAqzw"
   },
   "source": [
    "### Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce3f4b-63b2-4613-b614-9400a6543ba4",
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1710252504978,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -60
    },
    "id": "e2ce3f4b-63b2-4613-b614-9400a6543ba4"
   },
   "outputs": [],
   "source": [
    "import strategies\n",
    "import load_data\n",
    "import baselines\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import shap\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2c5dc30-59b5-4068-8821-dab06754776c",
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1710251269848,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -60
    },
    "id": "b2c5dc30-59b5-4068-8821-dab06754776c"
   },
   "outputs": [],
   "source": [
    "# Lerning Parametes\n",
    "num_local_epochs = 5\n",
    "num_rounds = 200\n",
    "\n",
    "# Learning Strategy\n",
    "strategy_name = \"FedAvg\"\n",
    "model_name = \"auto\"\n",
    "stepsize = 1.2\n",
    "weighted = True\n",
    "reset_per_round = False\n",
    "\n",
    "# Static Parameters\n",
    "batch_size= 64\n",
    "device = \"cuda\"\n",
    "test_set_fraction = 0.2\n",
    "\n",
    "# Analysis Parameters\n",
    "average_lxo = 2\n",
    "reputation_ts = 3\n",
    "\n",
    "# Logging\n",
    "log_per_round = True\n",
    "log_file = None\n",
    "averaging = \"weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2945293c-6ace-43e6-90c1-c8fe0130c982",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1710251272425,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -60
    },
    "id": "2945293c-6ace-43e6-90c1-c8fe0130c982"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"strategy_name\": strategy_name,\n",
    "    \"model_name\": model_name,\n",
    "    \"batch_size\":batch_size,\n",
    "\n",
    "    \"weighted\":weighted,\n",
    "    \"reset_per_round\":reset_per_round,\n",
    "\n",
    "    \"device\":device,\n",
    "    \"stepsize\":stepsize,\n",
    "    \"rounds\": num_rounds,\n",
    "    \"local_epochs\": num_local_epochs,\n",
    "    \"average_lxo\": average_lxo,\n",
    "    \"reputation_ts\": reputation_ts,\n",
    "\n",
    "    \"test_set_fraction\": test_set_fraction,\n",
    "\n",
    "    \"evaluation_averaging\": averaging,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4plzenrE3H7p",
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1710251134599,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -60
    },
    "id": "4plzenrE3H7p"
   },
   "outputs": [],
   "source": [
    "REGION = \"North\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14Wj6PHY7qQA",
   "metadata": {
    "id": "14Wj6PHY7qQA"
   },
   "source": [
    "## Contribution Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7YFglyo_8cT6",
   "metadata": {
    "id": "7YFglyo_8cT6"
   },
   "source": [
    "### Acquiring the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dTPOmYy-3cjr",
   "metadata": {
    "id": "dTPOmYy-3cjr"
   },
   "outputs": [],
   "source": [
    "# load the FL setting with REGION as hold-out region\n",
    "config = load_data.load_churn_dataset(config, column=\"state\")\n",
    "config = load_data.split_train_test(config, region=REGION, frac=config[\"test_set_fraction\"])\n",
    "\n",
    "# measure data imbalance among clients\n",
    "global_label_imbalance, local_label_imbalances, global_quantity_imbalance, local_quantity_imbalances, (global_cs_median, global_cs_stdev), local_label_distribution_imbalances, global_feature_imbalance, local_feature_imbalances = load_data.measure_imbalance(config, filename=log_file, log=False)\n",
    "imbalances = [[local_label_imbalances[x], local_quantity_imbalances[x],  local_label_distribution_imbalances[x], local_feature_imbalances[x]] for x in range(config[\"num_train_clients\"])]\n",
    "\n",
    "LDI = [local_label_distribution_imbalances[x] for x in range(config[\"num_train_clients\"])]\n",
    "LQI = [local_quantity_imbalances[x] for x in range(config[\"num_train_clients\"])]\n",
    "LLI = [x for x in list(local_label_imbalances.values())]\n",
    "LFI = [local_feature_imbalances[x] for x in range(config[\"num_train_clients\"])]\n",
    "\n",
    "GDI = [global_cs_median for x in range(len(LLI))]\n",
    "GQI = [global_quantity_imbalance for x in range(len(LLI))]\n",
    "GLI = [global_label_imbalance for x in range(len(LLI))]\n",
    "GFI = [global_feature_imbalance for x in range(len(LLI))]\n",
    "\n",
    "# Perform training\n",
    "learning_strategy = strategies.get_strategy_by_name(config)\n",
    "federated_model, federated_f1s = learning_strategy.run(config, filename=log_file, log_per_round=False, return_f1s=True)\n",
    "\n",
    "#Performance measurement\n",
    "acc, pre, rec, f1, _ = baselines.evaluatefederated_model, config[\"X_test\"], config[\"y_test\"], config, filename=log_file, log=False)\n",
    "\n",
    "# measure client contribution\n",
    "leave_out_performances, influences, reputations, cluster_imbalances, leave_out_clusters, _ = baselines.measure_contribution(federated_model, federated_f1s, config, imbalances, filename=log_file, log_per_round=True)\n",
    "\n",
    "contributions = []\n",
    "length = config[\"num_train_clients\"]\n",
    "correct_cluster_imbalances = leave_out_performances[-length:]\n",
    "for i in range(config[\"num_train_clients\"]):\n",
    "    for j, l in enumerate(leave_out_clusters):\n",
    "        if i in l:\n",
    "            contributions.append((f1 - correct_cluster_imbalances[j][3]) / len(l))\n",
    "\n",
    "# save to csv-file for subsequent training\n",
    "d = {\"Contribution\": contributions, \"Global Label Imbalance\": GLI, \"Global Distribution Imbalance\": GDI, \"Global Quantity Imbalance\": GQI, \"Global Feature Imbalance\": GFI, \"Local Label Imbalance\": LLI, \"Local Distribution Imbalance\": LDI, \"Local Quantity Imbalance\": LQI, \"Local Feature Imbalance\": LFI}\n",
    "\n",
    "if \"regions\" in config:\n",
    "    d[\"Regions\"] = config[\"regions\"]\n",
    "    d[\"States\"] = config[\"states\"]\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df.to_csv(\"./predictions/churn_\"+config[\"client_group\"]+\"_\"+config[\"test_region\"]+\"_\"+datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jyA4EycTyT4u",
   "metadata": {
    "id": "jyA4EycTyT4u"
   },
   "source": [
    "### Train the contribution regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a5vys8P9hXO",
   "metadata": {
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1710252450050,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -60
    },
    "id": "5a5vys8P9hXO"
   },
   "outputs": [],
   "source": [
    "# load dataframes from csv-files for region REGION\n",
    "files = [f for f in listdir(\"./predictions\") if isfile(join(\"./predictions\", f)) & f.startswith(\"churn_state_\"+REGION+\"_\")]\n",
    "\n",
    "dfs = []\n",
    "for filename in files:\n",
    "    df = pd.read_csv(\"./predictions/\"+filename)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4XsHdPUc9hMa",
   "metadata": {
    "id": "4XsHdPUc9hMa"
   },
   "outputs": [],
   "source": [
    "# train an regressor\n",
    "# instead of the RandomForestRegressor, any alternative can be provided\n",
    "y = df[\"Contribution\"].to_numpy().astype(float)\n",
    "df = df.drop([\"Contribution\"], axis=1)\n",
    "X = df.to_numpy().astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=150, max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Xp8vfyL-ofZ",
   "metadata": {
    "id": "6Xp8vfyL-ofZ"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"MAE:  \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE: \",mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WrBqSIHQ9grc",
   "metadata": {
    "id": "WrBqSIHQ9grc"
   },
   "source": [
    "## Contribution Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3rI7dpB0_zpn",
   "metadata": {
    "id": "3rI7dpB0_zpn"
   },
   "source": [
    "### Global understanding using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SOFfvTH9-7bu",
   "metadata": {
    "id": "SOFfvTH9-7bu"
   },
   "outputs": [],
   "source": [
    "# load SHAP explainer for the previously trained regressor\n",
    "explainer = shap.Explainer(clf)\n",
    "shap_values = explainer(np.array(X_test))\n",
    "feature_names = [\"GLI\",\"GDI\",\"GQI\",\"GFI\",\"LLI\", \"LDI\", \"LQI\", \"LFI\"]\n",
    "order = list(range(8))\n",
    "\n",
    "fig = shap.plots.beeswarm(shap_values, order=order, show=False)\n",
    "\n",
    "plt.xlabel(\"SHAP value\")\n",
    "plt.ylabel(\"Imbalance\")\n",
    "feature_names.reverse()\n",
    "plt.yticks(list(range(8)),feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oHf4Ourw_3ht",
   "metadata": {
    "id": "oHf4Ourw_3ht"
   },
   "source": [
    "### Local Understanding using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9yBQQgbhA4Ur",
   "metadata": {
    "id": "9yBQQgbhA4Ur"
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "# load SHAP explainer for the previously trained regressor\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# iterate instances to be explained\n",
    "for i in range(len(X_test)):\n",
    "    names = [\"GLI\",\"GDI\",\"GQI\",\"GFI\",\"LLI\", \"LDI\", \"LQI\", \"LFI\"]\n",
    "    names = [x+\"={:1.4f}\".format(X_test[i][n]) for n, x in enumerate(names)]\n",
    "\n",
    "    shap_plot = shap.force_plot(explainer.expected_value,\n",
    "        shap_values[i],\n",
    "        matplotlib=True, show=False,plot_cmap=['#77dd77', '#f99191'], feature_names=names)\n",
    "    plt.gcf()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rmz3gcP3BvNj",
   "metadata": {
    "id": "rmz3gcP3BvNj"
   },
   "source": [
    "# Federated Training\n",
    "Apply FL with all but the rejected clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "Qb57JoxLCcDz",
   "metadata": {
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1710253501195,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -60
    },
    "id": "Qb57JoxLCcDz"
   },
   "outputs": [],
   "source": [
    "# list of states excluded for each setting according to our input contorl\n",
    "d = {\n",
    "     \"Uncontrolled\":[],\n",
    "     \"North\": [\"PA\", \"AM\", \"AC\"],\n",
    "     \"Northeast\": [\"PE\", \"AL\", \"CE\", \"PB\"],\n",
    "     \"Center West\": [\"DF\"],\n",
    "     \"Southeast\": [\"SP\"],\n",
    "     \"South\": [\"RS\", \"PR\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zszV3M2rClAr",
   "metadata": {
    "id": "zszV3M2rClAr"
   },
   "outputs": [],
   "source": [
    "# perform training without excluded states\n",
    "config = load_data.load_churn_dataset(config, column=\"state\")\n",
    "config = load_data.split_train_test(config, region=0.2, exclude=d[REGION])\n",
    "learning_strategy = strategies.get_strategy_by_name(config)\n",
    "federated_model, federated_f1s = learning_strategy.run(config, filename=log_file, log_per_round=False, return_f1s=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ad6J_MDgZ7ll",
    "bhQN0YbCAulS",
    "veGd3LnPAxLl",
    "YSjauNw8A0Vi",
    "4by7t5-0BAhP",
    "A286TuR5BD7Q"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "name": "streamlit",
   "language": "python",
   "display_name": "Python (streamlit)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
